{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pokemon Scraper\n",
        "\n",
        "The goal of this notebook is to construct the dataset used for **RAG (Retrieval Augment Generation)** in PokepedAI."
      ],
      "metadata": {
        "id": "4iwvGeRoyZyk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Information\n",
        "\n",
        "So the firszt step in creating the dataset is to establish what information should be collected from and where.\n",
        "\n",
        "### Where to Collect Info\n",
        "\n",
        "So, considering the goal of PokepedAI is to serve as a chatbot one can use when playing Pokemon games, we can use a common source of information players typically use to get this infomation [PokemonDB](\n",
        "https://pokemondb.net)\n",
        "\n",
        "### What Info Should Be Collected\n",
        "\n",
        "PokemonDB contains a lot of information overall about Pokemon but included in the documents will be information for the most common questions people will ask:\n",
        "\n",
        "```\n",
        "What type is <Pokemon>?\n",
        "What are the base stats of <Pokemon>?\n",
        "How does <Pokemon A> compare to <Pokemon B>?\n",
        "\n",
        "How do I evolve <Pokemon>?\n",
        "What level does <Pokemon> evolve?\n",
        "What can <Pokemon> evolve into?\n",
        "\n",
        "What abilities does <Pokemon> have?\n",
        "What is <Pokemon>'s hidden ability?\n",
        "Which Pokemon have <Ability>?\n",
        "What does <Ability> do?\n",
        "\n",
        "What moves does <Pokemon> learn by level-up?\n",
        "What TMs can <Pokemon> learn?\n",
        "Can <Pokemon> learn <Move>?\n",
        "Which Pokemon can learn <Move>?\n",
        "When does <Pokemon> learn <Move>?\n",
        "\n",
        "What are <Pokemon>'s weaknesses?\n",
        "What is super effective against <Pokemon>?\n",
        "Which Pokemon resist <Type>?\n",
        "\n",
        "Where can I find <Pokemon> in <Game>?\n",
        "Which Pokemon appear in <Location> in <Game>?\n",
        "Which Pokemon are version exclusives in <Game>?\n",
        "\n",
        "What egg group is <Pokemon>?\n",
        "Which Pokemon share an egg group with <Pokemon>?\n",
        "Can <Pokemon> breed?\n",
        "\n",
        "What forms does <Pokemon> have?\n",
        "What is the type of <Form/Variant>?\n",
        "What differs between <Form A> and <Form B>?\n",
        "\n",
        "What changed for <Pokemon> across generations?\n",
        "Was <Pokemon> obtainable in <Generation>?\n",
        "Did <Move> change between generations?\n",
        "```\n",
        "\n",
        "Thus, information on the site such as such as the pokemon name in diffferent languages and its flavor text (information suplerfious to gameplay related questions) will not be included."
      ],
      "metadata": {
        "id": "yj6Ntgony6gH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating RAG Chunks\n",
        "\n",
        "While creating this dataset, especially for Pokemon specific information, since much of it is organized into tables and charts, which does not translate well into a RAG (which likes natural language styled documents), we will convert such information into a natural language text while keeping the raw information as metadata.\n",
        "\n",
        "In addition, to help with indexing, all information will be split into smaller json sections based on the information they hold. Since this document is mostly consistent of fact based information (Pokemon move stats, Pokemon stats) that does not rely too much on broader context, these RAG chunks will be broken into small sections in order to ensure more acurracy."
      ],
      "metadata": {
        "id": "L6ilYwwT0k_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attributions\n",
        "\n",
        "*   The initial template for scraping this code comes from work done from this [repository](https://github.com/christian-jaimes/pokemon-data-scraping). This includes the general setup of the webscraper and most of the code for listing basic pokemon information.\n",
        "*   The boilerplate code for retrieving the rest of the information needed as well as creating the data chunks in generated by ChatGPT, however they are cleaned and commented for methodology purposes afterwards by me.\n",
        "\n"
      ],
      "metadata": {
        "id": "uhYtC9pF2JIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Code"
      ],
      "metadata": {
        "id": "VLMasrrB04h1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "rndie6z12_gp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "id": "kJ1LQfBwv4ii"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from bs4 import BeautifulSoup, Tag"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constants + Helper Methods"
      ],
      "metadata": {
        "id": "Z2RzvP3h3Lre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_name = 'pokemon-test-1'             # project name, base text for output files\n",
        "\n",
        "full_dataset = False                        # if True, will scrape whole database\n",
        "part_dataset = 250                          # if False, scrape the first 20"
      ],
      "metadata": {
        "id": "9mkbfKnZ2XuJ"
      },
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_to_str(l:list):\n",
        "    \"\"\"\n",
        "    Given a list of items, convert to comma and separated string.\n",
        "    \"\"\"\n",
        "    if len(l) == 1:\n",
        "        s = l[0]\n",
        "    elif len(l) == 2:\n",
        "        s = \" and \".join(l)\n",
        "    else:\n",
        "        s = \", \".join(l[:-1]) + f\", and {l[-1]}\"\n",
        "\n",
        "    return s\n",
        "\n",
        "\n",
        "def remove_parentheses(method_raw: str) -> str:\n",
        "    \"\"\"Strip wrapping parentheses from things like '(Level 16)'.\"\"\"\n",
        "    return method_raw.strip().strip(\"()\")"
      ],
      "metadata": {
        "id": "985OU_y8Ki4g"
      },
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building RAG Chunks"
      ],
      "metadata": {
        "id": "eHTVw89S3mAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_core_doc(info: dict):\n",
        "    name = info.get(\"name\")\n",
        "    natdex = info.get(\"id\")\n",
        "    desc = info.get(\"description\")\n",
        "    species = info.get(\"species\")\n",
        "    types = info.get(\"types\") or []\n",
        "    generation = info.get(\"generation\")\n",
        "    height = info.get(\"height\")\n",
        "    weight = info.get(\"weight\")\n",
        "    abilities = info.get(\"abilities\") or []\n",
        "    name_etymology = info.get(\"name_etymology\")\n",
        "\n",
        "    clean_types = [t for t in types if t]\n",
        "    if clean_types:\n",
        "        type_str = \"/\".join(clean_types)\n",
        "    else:\n",
        "        type_str = \"unknown\"\n",
        "\n",
        "    gen_str = f\"Generation {generation}\" if generation else \"an unknown generation\"\n",
        "\n",
        "    raw_abilities = info.get(\"abilities\")\n",
        "\n",
        "    if isinstance(raw_abilities, str):\n",
        "        abilities_list = [a.strip() for a in raw_abilities.split(\",\") if a.strip()]\n",
        "    elif isinstance(raw_abilities, (list, tuple, set)):\n",
        "        abilities_list = [str(a).strip() for a in raw_abilities if a]\n",
        "    else:\n",
        "        abilities_list = []\n",
        "    if abilities_list:\n",
        "        abil_str = list_to_str(abilities_list)\n",
        "\n",
        "    text_parts = []\n",
        "    text_parts.append(f\"{name} is a {type_str}-type Pokémon introduced in {gen_str}.\")\n",
        "    if natdex is not None:\n",
        "        text_parts.append(f\"It is number {natdex} in the National Pokédex.\")\n",
        "    if species:\n",
        "        text_parts.append(f\"{name} is classified as the {species} Pokémon.\")\n",
        "    if height is not None or weight is not None:\n",
        "        hw_parts = []\n",
        "        if height is not None:\n",
        "            hw_parts.append(f\"is {height} tall\")\n",
        "        if weight is not None:\n",
        "            hw_parts.append(f\"weighs {weight}\")\n",
        "        if hw_parts:\n",
        "            text_parts.append(f\"{name} \" + \" and \".join(hw_parts) + \".\")\n",
        "    text_parts.append(f\"{name} can have the abilities {abil_str}.\")\n",
        "    if name_etymology:\n",
        "        text_parts.append(f\"Its name is derived from {name_etymology}.\")\n",
        "\n",
        "    text = \" \".join(text_parts).strip()\n",
        "\n",
        "    return {\n",
        "        \"id\": f\"{name}-core\" if name else f\"{natdex}-core\",\n",
        "        \"pokemon\": name,\n",
        "        \"section\": \"core\",\n",
        "        \"description\": desc,\n",
        "        \"text\": text,\n",
        "        \"metadata\": {\n",
        "            \"National Dex Number\": natdex,\n",
        "            \"Types\": clean_types,\n",
        "            \"Generatin\": generation,\n",
        "            \"Species\": species,\n",
        "            \"Height\": height,\n",
        "            \"Weight\": weight,\n",
        "            \"Abilities\": abilities_list,\n",
        "            \"Name Etymology\": name_etymology,\n",
        "        },\n",
        "    }\n"
      ],
      "metadata": {
        "id": "PIj7wxOw52aa"
      },
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_training_doc(info: dict):\n",
        "    name = info[\"name\"]\n",
        "    ev_yield = info[\"ev_yield\"]\n",
        "    catch_rate = info[\"catch_rate\"]\n",
        "    base_friendship = info[\"base_friendship\"]\n",
        "    base_exp = info[\"base_exp\"]\n",
        "    growth_rate = info[\"growth_rate\"]\n",
        "\n",
        "    if isinstance(ev_yield, str):\n",
        "        ev_list = [a.strip() for a in ev_yield.split(\",\") if a.strip()]\n",
        "    elif isinstance(ev_yield, (list, tuple, set)):\n",
        "        ev_list = [str(a).strip() for a in ev_yield if a]\n",
        "    else:\n",
        "        ev_list = []\n",
        "    if ev_list:\n",
        "        ev_str = list_to_str(ev_list)\n",
        "\n",
        "    text_parts = []\n",
        "    text_parts.append(f\"For training purposes, defeating {name} yields {ev_str} EVs.\")\n",
        "    text_parts.append(f\"It grants {base_exp} base experience points and follows a {growth_rate} experience growth rate.\")\n",
        "    text_parts.append(f\"{name} has a catch rate of {catch_rate} and a base friendship of {base_friendship}.\")\n",
        "\n",
        "    text = \" \".join(text_parts)\n",
        "\n",
        "    return {\n",
        "        \"id\": f\"{name}-training\",\n",
        "        \"pokemon\": name,\n",
        "        \"section\": \"training\",\n",
        "        \"text\": text,\n",
        "        \"metadata\": {\n",
        "            \"EV Yield\": ev_yield,\n",
        "            \"Catch Rate\": catch_rate,\n",
        "            \"Base Friendship\": base_friendship,\n",
        "            \"Base Experience\": base_exp,\n",
        "            \"Growth Rate\": growth_rate,\n",
        "        },\n",
        "    }\n"
      ],
      "metadata": {
        "id": "KMs9Co-FH2Rm"
      },
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_breeding_doc(info: dict):\n",
        "    name = info[\"name\"]\n",
        "    egg_groups = info[\"egg_groups\"]\n",
        "    gender_male = info[\"gender_male\"]\n",
        "    gender_female = info[\"gender_female\"]\n",
        "    egg_cycles = info[\"egg_cycles\"]\n",
        "\n",
        "    if isinstance(egg_groups, str):\n",
        "        egg_list = [a.strip() for a in egg_groups.split(\",\") if a.strip()]\n",
        "    elif isinstance(egg_groups, (list, tuple, set)):\n",
        "        egg_list = [str(a).strip() for a in egg_groups if a]\n",
        "    else:\n",
        "        egg_list = []\n",
        "    if egg_list:\n",
        "        egg_str = list_to_str(egg_list)\n",
        "\n",
        "    if gender_male == 0 and gender_female == 0:\n",
        "        gender_text = f\"{name} is a genderless species.\"\n",
        "    else:\n",
        "        gender_text = (\n",
        "            f\"The typical gender ratio for {name} is \"\n",
        "            f\"{gender_male}% male and {gender_female}% female.\"\n",
        "        )\n",
        "\n",
        "    hatch_text_split = egg_cycles.split(\" \")\n",
        "    egg_cycles_str = hatch_text_split[0]\n",
        "    steps = \" \".join(hatch_text_split[1:])\n",
        "\n",
        "    text_parts = []\n",
        "    text_parts.append(f\"{name} belongs to the {egg_str} Egg Group.\")\n",
        "    text_parts.append(gender_text)\n",
        "    text_parts.append(f\"Eggs take {egg_cycles_str} egg cycles {steps} to hatch.\")\n",
        "    text = \" \".join(text_parts)\n",
        "\n",
        "    return {\n",
        "        \"id\": f\"{name}-breeding\",\n",
        "        \"pokemon\": name,\n",
        "        \"section\": \"breeding\",\n",
        "        \"text\": text,\n",
        "        \"metadata\": {\n",
        "            \"eggGroups\": egg_groups,\n",
        "            \"genderMale\": gender_male,\n",
        "            \"genderFemale\": gender_female,\n",
        "            \"eggCycles\": egg_cycles,\n",
        "        },\n",
        "    }\n"
      ],
      "metadata": {
        "id": "VvQpKKJ6JUQg"
      },
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_statistics_doc(info: dict):\n",
        "    name = info[\"name\"]\n",
        "\n",
        "    hp = info[\"base_hp\"]\n",
        "    atk = info[\"base_atk\"]\n",
        "    dfc = info[\"base_def\"]\n",
        "    satk = info[\"base_satk\"]\n",
        "    sdfc = info[\"base_sdef\"]\n",
        "    spd = info[\"base_spd\"]\n",
        "    total = int(hp) + int(atk) + int(dfc) + int(satk) + int(sdfc) + int(spd)\n",
        "\n",
        "    min_hp = info[\"min_hp\"]\n",
        "    max_hp = info[\"max_hp\"]\n",
        "    min_atk = info[\"min_atk\"]\n",
        "    max_atk = info[\"max_atk\"]\n",
        "    min_def = info[\"min_def\"]\n",
        "    max_def = info[\"max_def\"]\n",
        "    min_satk = info[\"min_satk\"]\n",
        "    max_satk = info[\"max_satk\"]\n",
        "    min_sdef = info[\"min_sdef\"]\n",
        "    max_sdef = info[\"max_sdef\"]\n",
        "    min_spd = info[\"min_spd\"]\n",
        "    max_spd = info[\"max_spd\"]\n",
        "\n",
        "    text = (\n",
        "        f\"{name} has a base stat total of {total}, with base stats of \"\n",
        "        f\"{hp} HP, {atk} Attack, {dfc} Defense, {satk} Special Attack, \"\n",
        "        f\"{sdfc} Special Defense, and {spd} Speed. \"\n",
        "        f\"At level 100, {name}'s HP can range from {min_hp} to {max_hp}, \"\n",
        "        f\"Attack from {min_atk} to {max_atk}, Defense from {min_def} to {max_def}, \"\n",
        "        f\"Special Attack from {min_satk} to {max_satk}, \"\n",
        "        f\"Special Defense from {min_sdef} to {max_sdef}, \"\n",
        "        f\"and Speed from {min_spd} to {max_spd}, depending on its nature, IVs, and EVs.\"\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"id\": f\"{name}-statistics\",\n",
        "        \"pokemon\": name,\n",
        "        \"section\": \"statistics\",\n",
        "        \"text\": text,\n",
        "        \"metadata\": {\n",
        "            \"baseStats\": {\n",
        "                \"hp\": hp,\n",
        "                \"attack\": atk,\n",
        "                \"defense\": dfc,\n",
        "                \"spAttack\": satk,\n",
        "                \"spDefense\": sdfc,\n",
        "                \"speed\": spd,\n",
        "            },\n",
        "            \"baseStatTotal\": total,\n",
        "            \"minStatsLevel100\": {\n",
        "                \"hp\": min_hp,\n",
        "                \"attack\": min_atk,\n",
        "                \"defense\": min_def,\n",
        "                \"spAttack\": min_satk,\n",
        "                \"spDefense\": min_sdef,\n",
        "                \"speed\": min_spd,\n",
        "            },\n",
        "            \"maxStatsLevel100\": {\n",
        "                \"hp\": max_hp,\n",
        "                \"attack\": max_atk,\n",
        "                \"defense\": max_def,\n",
        "                \"spAttack\": max_satk,\n",
        "                \"spDefense\": max_sdef,\n",
        "                \"speed\": max_spd,\n",
        "            },\n",
        "        },\n",
        "    }\n"
      ],
      "metadata": {
        "id": "0MOVjoI5MNkE"
      },
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_evolution_doc(pokemon_data: dict, soup):\n",
        "    pokemon_name = pokemon_data[\"name\"]\n",
        "    pokemon_id = pokemon_data[\"id\"]\n",
        "\n",
        "    # retrieve all evolution edges\n",
        "    all_edges = parse_all_evolution_edges(soup)\n",
        "\n",
        "    # keep only edges this pokemon in\n",
        "    incoming = [e for e in all_edges if e[\"to\"] == pokemon_name]\n",
        "    outgoing = [e for e in all_edges if e[\"from\"] == pokemon_name]\n",
        "\n",
        "    # if there is no evolution\n",
        "    if not incoming and not outgoing:\n",
        "        return {\n",
        "            \"id\": f\"{pokemon_name}-evolutions\",\n",
        "            \"pokemon\": pokemon_name,\n",
        "            \"section\": \"evolutions\",\n",
        "            \"text\": f\"{pokemon_name} does not evolve.\",\n",
        "            \"metadata\": {\n",
        "                \"pokemon_id\": pokemon_id,\n",
        "                \"pokemon_name\": pokemon_name,\n",
        "                \"evolution_edges\": [],\n",
        "                \"has_evolutions\": False,\n",
        "            },\n",
        "        }\n",
        "\n",
        "    text_parts = []\n",
        "\n",
        "    # pre-evolution -> this pokemon\n",
        "    for e in incoming:\n",
        "        method_clean = remove_parentheses(e[\"method\"])\n",
        "        text_parts.append(\n",
        "            f\"{e['from']} evolves into {pokemon_name} via {method_clean}.\"\n",
        "        )\n",
        "\n",
        "    # this pokemon -> later evolutions\n",
        "    if len(outgoing) == 1:\n",
        "        e = outgoing[0]\n",
        "        method_clean = remove_parentheses(e[\"method\"])\n",
        "        text_parts.append(\n",
        "            f\"{pokemon_name} evolves into {e['to']} via {method_clean}.\"\n",
        "        )\n",
        "    elif len(outgoing) > 1:\n",
        "        branch_parts = []\n",
        "        for e in outgoing:\n",
        "            method_clean = remove_parentheses(e[\"method\"])\n",
        "            branch_parts.append(f\"{e['to']} via {method_clean}\")\n",
        "\n",
        "        branches_text = list_to_str(branch_parts)\n",
        "\n",
        "        text_parts.append(f\"{pokemon_name} can evolve into {branches_text}.\")\n",
        "\n",
        "    text = \" \".join(text_parts)\n",
        "    relevant_edges = incoming + outgoing\n",
        "\n",
        "    return {\n",
        "        \"id\": f\"{pokemon_name.lower()}-evolutions\",\n",
        "        \"pokemon\": pokemon_name,\n",
        "        \"section\": \"evolutions\",\n",
        "        \"text\": text,\n",
        "        \"metadata\": {\n",
        "            \"pokemon_id\": pokemon_id,\n",
        "            \"pokemon_name\": pokemon_name,\n",
        "            \"evolution_edges\": relevant_edges,\n",
        "            \"has_evolutions\": True,\n",
        "        },\n",
        "    }"
      ],
      "metadata": {
        "id": "qacLPSSC5nhz"
      },
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_moves_docs_for_generation(pokemon_data: dict, gen, moves_soup):\n",
        "    pokemon_name = pokemon_data[\"name\"]\n",
        "    pokemon_id = pokemon_data[\"id\"]\n",
        "\n",
        "    sections = parse_moves_sections(moves_soup)\n",
        "\n",
        "    grouped = {}  # key: (game_group, method)\n",
        "\n",
        "    for sec in sections:\n",
        "        games_text = sec[\"games_text\"]\n",
        "        method = sec[\"method\"]\n",
        "        rows = sec[\"rows\"]\n",
        "\n",
        "        # get the game group, create the key\n",
        "        game_group = infer_game_group_id(games_text)\n",
        "        key = (game_group, method)\n",
        "\n",
        "        group = grouped.setdefault(\n",
        "            key,\n",
        "            {\n",
        "                \"game_group\": game_group,\n",
        "                \"method\": method,\n",
        "                \"games_text_samples\": set(),\n",
        "                \"rows\": [],\n",
        "            },\n",
        "        )\n",
        "\n",
        "        # add the game text above the table\n",
        "        if games_text:\n",
        "            group[\"games_text_samples\"].add(games_text)\n",
        "        # add all the moves\n",
        "        group[\"rows\"].extend(rows)\n",
        "\n",
        "    method_phrases = {\n",
        "        \"level-up\": \"By level up\",\n",
        "        \"evolution\": \"On evolution\",\n",
        "        \"egg\": \"By egg moves\",\n",
        "        \"pre-evo\": \"From pre-evolutions\",\n",
        "        \"tm\": \"By TM\",\n",
        "        \"hm\": \"By HM\",\n",
        "        \"tr\": \"By TR\",\n",
        "        \"tutor\": \"From move tutors\",\n",
        "        \"transfer\": \"As transfer-only moves\",\n",
        "    }\n",
        "\n",
        "    chunks = []\n",
        "\n",
        "    # for each game_group, method make a chunk\n",
        "    for (game_group, method), group in grouped.items():\n",
        "        rows = group[\"rows\"]\n",
        "        games_texts = list(group[\"games_text_samples\"])\n",
        "\n",
        "        has_any_moves = bool(rows)\n",
        "        has_any_text = bool(games_texts)\n",
        "\n",
        "        if not has_any_moves and not has_any_text:\n",
        "            continue\n",
        "\n",
        "        text_parts = []\n",
        "\n",
        "        if games_texts:\n",
        "            text_parts.append(\" \".join(games_texts))\n",
        "\n",
        "        if rows:\n",
        "            if method == \"level-up\":\n",
        "                move_list = \", \".join(f\"{r.get('move')} (Lv. {r.get('level')})\" for r in rows)\n",
        "            elif method in (\"tm\", \"hm\", \"tr\"):\n",
        "                move_list = \", \".join(f\"{r.get('machine')} {r.get('move')}\" for r in rows)\n",
        "            else:\n",
        "                move_list = \", \".join(r.get(\"move\") for r in rows)\n",
        "\n",
        "            prefix = method_phrases.get(method)\n",
        "            text_parts.append(f\"{prefix} it can learn: {move_list}.\")\n",
        "\n",
        "        text = (\n",
        "            \" \".join(text_parts)\n",
        "            or f\"No moves recorded for {pokemon_name} in generation {gen} ({game_group}, {method}).\"\n",
        "        )\n",
        "\n",
        "        chunk = {\n",
        "            \"id\": f\"{pokemon_name.lower()}-moves-gen{gen}-{game_group}-{method}\",\n",
        "            \"pokemon\": pokemon_name,\n",
        "            \"section\": \"moves\",\n",
        "            \"text\": text,\n",
        "            \"metadata\": {\n",
        "                \"pokemon_id\": pokemon_id,\n",
        "                \"pokemon_name\": pokemon_name,\n",
        "                \"generation\": gen,\n",
        "                \"game_group\": game_group,\n",
        "                \"method\": method,\n",
        "                \"games_text_samples\": games_texts,\n",
        "            },\n",
        "        }\n",
        "        chunks.append(chunk)\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "WyVPMYzB7O6w"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_locations_doc(pokemon_data: dict, pokemon_soup):\n",
        "    pokemon_id = pokemon_data[\"id\"]\n",
        "    pokemon_name = pokemon_data[\"name\"]\n",
        "\n",
        "    location_entries = parse_locations_section(pokemon_soup)\n",
        "\n",
        "    if not location_entries:\n",
        "        text = (\n",
        "            f\"{pokemon_name} does not have location data.\"\n",
        "        )\n",
        "        has_locations = False\n",
        "    else:\n",
        "        has_locations = True\n",
        "\n",
        "        # get pokemon normal locatons\n",
        "        normal_entries = [\n",
        "            e for e in location_entries\n",
        "            if e[\"availability\"] == \"normal\" and e[\"location_names\"]\n",
        "        ]\n",
        "\n",
        "        # map location to all games where pokemon is located there\n",
        "        by_location: dict[str, list[str]] = {}\n",
        "        for e in normal_entries:\n",
        "            loc = e[\"raw_location\"]\n",
        "            by_location.setdefault(loc, []).append(e[\"game\"])\n",
        "\n",
        "        # location string Pallet Town (Red, Blue)\n",
        "        location_bits = []\n",
        "        for loc, games in by_location.items():\n",
        "            games_str = \", \".join(sorted(set(games)))\n",
        "            location_bits.append(f\"{loc} ({games_str})\")\n",
        "\n",
        "        text_parts = []\n",
        "\n",
        "        if location_bits:\n",
        "            text_parts.append(\n",
        "                f\"{pokemon_name} can be found in the following locations in the core series games: \"\n",
        "                + list_to_str(location_bits)\n",
        "                + \".\"\n",
        "            )\n",
        "\n",
        "        # get pokemon special locations\n",
        "        special_entries = [e for e in location_entries if e[\"availability\"] != \"normal\"]\n",
        "\n",
        "        if special_entries:\n",
        "            # get the kinds of special locations for this pokemon\n",
        "            kinds = sorted(set(e[\"availability\"] for e in special_entries))\n",
        "            phrases_map = {\n",
        "                \"transfer-only\": \"only obtainable by trading or transferring from other games\",\n",
        "                \"event-only\": \"only obtainable via special events or distributions\",\n",
        "                \"not-available\": \"not obtainable in-game\",\n",
        "                \"unknown\": \"with locations that have not yet been documented\",\n",
        "            }\n",
        "\n",
        "            # map the kind to the phrase\n",
        "            phrases = [phrases_map[k] for k in kinds if k in phrases_map]\n",
        "            if phrases:\n",
        "                text_parts.append(\n",
        "                    f\"In some titles, {pokemon_name} is \"\n",
        "                    + list_to_str(phrases)\n",
        "                    + \".\"\n",
        "                )\n",
        "\n",
        "        text = \" \".join(text_parts)\n",
        "\n",
        "    return {\n",
        "        \"id\": f\"{pokemon_name.lower()}-locations\",\n",
        "        \"pokemon\": pokemon_name,\n",
        "        \"section\": \"locations\",\n",
        "        \"text\": text,\n",
        "        \"metadata\": {\n",
        "            \"pokemon_id\": pokemon_id,\n",
        "            \"pokemon_name\": pokemon_name,\n",
        "            \"locations\": location_entries,\n",
        "            \"has_locations\": has_locations,\n",
        "        },\n",
        "    }"
      ],
      "metadata": {
        "id": "o1eWTwUT9sp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Methods to Parse Information from HTML\n"
      ],
      "metadata": {
        "id": "_5k5yYbMAf_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pokemon_data(pokemon_soup)\n",
        "    ###### Data Parsing\n",
        "    ### Pokemon Info\n",
        "    pokemon_id = int(pokemon_soup.find(\"th\", string=\"National №\").find_next(\"td\").text)\n",
        "\n",
        "    pokemon_name = pokemon_soup.find(\"h1\").text.strip()\n",
        "\n",
        "    pokemon_desc = pokemon_soup.find('div', class_='tabset-basics').find_all_previous(\"p\")\n",
        "    pokemon_desc = '|'.join(desc.text.strip() for desc in pokemon_desc).split('|')[::-1]\n",
        "    pokemon_desc = ' '.join(pokemon_desc)\n",
        "\n",
        "    species_data = pokemon_soup.find(\"th\", string=\"Species\").find_next(\"td\").text.strip().replace(\" Pokémon\", \"\")\n",
        "\n",
        "    height = pokemon_soup.find(\"th\", string=\"Height\").find_next(\"td\").text.strip()\n",
        "    weight = pokemon_soup.find(\"th\", string=\"Weight\").find_next(\"td\").text.strip()\n",
        "\n",
        "    type_elements = pokemon_soup.find(\"th\", string=\"Type\").find_next(\"td\").find_all(\"a\")\n",
        "    type_info = ', '.join(type_element.text.strip() for type_element in type_elements).split(',')\n",
        "    type_1 = type_info[0]\n",
        "    if len(type_info) == 1:\n",
        "        type_2 = None\n",
        "    else:\n",
        "        type_2 = type_info[1].strip()\n",
        "\n",
        "    generation_title_element = pokemon_soup.find(class_=\"list-nav-title\", string='In other generations')\n",
        "    if generation_title_element:\n",
        "        generation_all = generation_title_element.find_next_siblings('li')\n",
        "        in_generation = ', '.join(generation_select.text.strip() for generation_select in generation_all)\n",
        "    else:\n",
        "        in_generation = '9'\n",
        "    generation = int(in_generation[0])\n",
        "\n",
        "    name_etymology_element = pokemon_soup.find(class_=\"list-nav-title\", string='In other generations')\n",
        "    if name_etymology_element:\n",
        "        name_etymology_piece = pokemon_soup.find(\"dl\", class_=\"etymology\").find_all('dt')\n",
        "        name_etymology_desc = pokemon_soup.find(\"dl\", class_=\"etymology\").find_all('dd')\n",
        "        name_etymology = [f\"{dt.text.strip()}: {dd.text.strip()}\" for dt, dd in zip(name_etymology_piece, name_etymology_desc)]\n",
        "        name_etymology = \" | \".join(name_etymology)\n",
        "\n",
        "    ability_elements = pokemon_soup.find(\"th\", string=\"Abilities\").find_next(\"td\").find_all(\"a\")\n",
        "    abilities = ', '.join(ability_element.text.strip() for ability_element in ability_elements)\n",
        "\n",
        "    ### Training Info\n",
        "    ev_yield = pokemon_soup.find(\"th\", string=\"EV yield\").find_next(\"td\").text.strip()\n",
        "\n",
        "    catch_rate = pokemon_soup.find(\"th\", string=\"Catch rate\").find_next(\"td\").text.strip().split()[0]\n",
        "\n",
        "    base_friendship = pokemon_soup.find(\"th\", string=\"Base Exp.\").find_previous(\"td\").text.strip().split()[0]\n",
        "\n",
        "    base_exp = pokemon_soup.find(\"th\", string=\"Base Exp.\").find_next(\"td\").text.strip().split()[0]\n",
        "\n",
        "    growth_rate = pokemon_soup.find(\"th\", string=\"Growth Rate\").find_next(\"td\").text.strip()\n",
        "\n",
        "    ### Breeding Info\n",
        "    gender = pokemon_soup.find(\"th\", string=\"Gender\").find_next(\"td\").text.strip().split(', ')\n",
        "    if len(gender) > 1:\n",
        "        gender_male = gender[0]\n",
        "        gender_male = gender_male.split('%')[0]\n",
        "    else:\n",
        "        gender_male = '0'\n",
        "    if len(gender) > 1:\n",
        "        gender_female = gender[1]\n",
        "        gender_female = gender_female.split('%')[0]\n",
        "    else:\n",
        "        gender_female = '0'\n",
        "\n",
        "    egg_groups = pokemon_soup.find(\"th\", string=\"Egg Groups\").find_next(\"td\").text.strip().split(', ')\n",
        "\n",
        "    egg_cycles = pokemon_soup.find(\"th\", string=\"Egg cycles\").find_next(\"td\").text.replace(\"\\t\\t\\t\\t\", \" \").strip()\n",
        "\n",
        "\n",
        "    ### Pokemon Stats\n",
        "    hp_elements = pokemon_soup.find(\"th\", string=\"HP\").find_next_siblings(\"td\", class_=\"cell-num\")\n",
        "    hp_stats = [hp_element.text.strip() for hp_element in hp_elements]\n",
        "    base_hp, min_hp, max_hp = hp_stats\n",
        "\n",
        "    atk_elements = pokemon_soup.find(\"th\", string=\"Attack\").find_next_siblings(\"td\", class_=\"cell-num\")\n",
        "    atk_stats = [atk_element.text.strip() for atk_element in atk_elements]\n",
        "    base_atk, min_atk, max_atk = atk_stats\n",
        "\n",
        "    def_elements = pokemon_soup.find(\"th\", string=\"Defense\").find_next_siblings(\"td\", class_=\"cell-num\")\n",
        "    def_stats = [def_element.text.strip() for def_element in def_elements]\n",
        "    base_def, min_def, max_def = def_stats\n",
        "\n",
        "    satk_elements = pokemon_soup.find(\"th\", string=\"Sp. Atk\").find_next_siblings(\"td\", class_=\"cell-num\")\n",
        "    satk_stats = [satk_element.text.strip() for satk_element in satk_elements]\n",
        "    base_satk, min_satk, max_satk = satk_stats\n",
        "\n",
        "    sdef_elements = pokemon_soup.find(\"th\", string=\"Sp. Def\").find_next_siblings(\"td\", class_=\"cell-num\")\n",
        "    sdef_stats = [sdef_element.text.strip() for sdef_element in sdef_elements]\n",
        "    base_sdef, min_sdef, max_sdef = sdef_stats\n",
        "\n",
        "    spd_elements = pokemon_soup.find(\"th\", string=\"Speed\").find_next_siblings(\"td\", class_=\"cell-num\")\n",
        "    spd_stats = [spd_element.text.strip() for spd_element in spd_elements]\n",
        "    base_spd, min_spd, max_spd = spd_stats\n",
        "\n",
        "    return {\n",
        "        \"description\": pokemon_desc,\n",
        "\n",
        "        \"id\": pokemon_id,\n",
        "        \"name\": pokemon_name,\n",
        "        \"species\": species_data,\n",
        "        \"height\": height,\n",
        "        \"weight\": weight,\n",
        "        \"types\": [type_1, type_2],\n",
        "        \"generation\": generation,\n",
        "        \"name_etymology\": name_etymology,\n",
        "        \"abilities\": abilities,\n",
        "\n",
        "        \"ev_yield\": ev_yield,\n",
        "        \"catch_rate\": catch_rate,\n",
        "        \"base_friendship\": base_friendship,\n",
        "        \"base_exp\": base_exp,\n",
        "        \"growth_rate\": growth_rate,\n",
        "\n",
        "        \"egg_groups\": egg_groups,\n",
        "        \"gender_male\": gender_male,\n",
        "        \"gender_female\": gender_female,\n",
        "        \"egg_cycles\": egg_cycles,\n",
        "\n",
        "        \"base_hp\": base_hp,\n",
        "        \"min_hp\": min_hp,\n",
        "        \"max_hp\": max_hp,\n",
        "        \"base_atk\": base_atk,\n",
        "        \"min_atk\": min_atk,\n",
        "        \"max_atk\": max_atk,\n",
        "        \"base_def\": base_def,\n",
        "        \"min_def\": min_def,\n",
        "        \"max_def\": max_def,\n",
        "        \"base_satk\": base_satk,\n",
        "        \"min_satk\": min_satk,\n",
        "        \"max_satk\": max_satk,\n",
        "        \"base_sdef\": base_sdef,\n",
        "        \"min_sdef\": min_sdef,\n",
        "        \"max_sdef\": max_sdef,\n",
        "        \"base_spd\": base_spd,\n",
        "        \"min_spd\": min_spd,\n",
        "        \"max_spd\": max_spd,\n",
        "    }"
      ],
      "metadata": {
        "id": "wczJjDw6At6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_evo_card(card):\n",
        "    # from a single card element, get the information\n",
        "    name_el = card.select_one(\"a.ent-name\")\n",
        "    if not name_el:\n",
        "        return {}\n",
        "\n",
        "    name = name_el.get_text(strip=True)\n",
        "    num_el = card.select_one(\"span.infocard-lg-data small\")\n",
        "    dex_number = num_el.get_text(strip=True) if num_el else None\n",
        "\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"dex_number\": dex_number\n",
        "    }\n",
        "\n",
        "\n",
        "def parse_all_evolution_edges(soup):\n",
        "    edges = []\n",
        "\n",
        "    # split evolution (one pre-evolution can go to multiple future)\n",
        "    for evo_split in soup.select(\"span.infocard-evo-split\"):\n",
        "        # the pre evolution card\n",
        "        base_card = evo_split.find_previous(\"div\", class_=\"infocard\")\n",
        "        if not base_card:\n",
        "            continue\n",
        "        base_info = extract_evo_card(base_card)\n",
        "        if not base_info:\n",
        "            continue\n",
        "\n",
        "        # each direct child is a from card from this base one\n",
        "        for child in evo_split.children:\n",
        "            if not getattr(child, \"get\", None):\n",
        "                continue\n",
        "            if \"infocard-list-evo\" not in (child.get(\"class\") or []):\n",
        "                continue\n",
        "\n",
        "            arrow = child.select_one(\"span.infocard-arrow\")\n",
        "            target_card = child.find(\"div\", class_=\"infocard\")\n",
        "\n",
        "            if not arrow or not target_card:\n",
        "                continue\n",
        "\n",
        "            method_text = arrow.get_text(\" \", strip=True)\n",
        "            target_info = extract_evo_card(target_card)\n",
        "            if not target_info:\n",
        "                continue\n",
        "\n",
        "            edges.append(\n",
        "                {\n",
        "                    \"from\": base_info[\"name\"],\n",
        "                    \"from_dex\": base_info[\"dex_number\"],\n",
        "                    \"to\": target_info[\"name\"],\n",
        "                    \"to_dex\": target_info[\"dex_number\"],\n",
        "                    \"method\": method_text,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    # linear evolution (only to one)\n",
        "    for arrow in soup.select(\"span.infocard-arrow\"):\n",
        "        # skip arrows that are already handled inside a split\n",
        "        if arrow.find_parent(\"span\", class_=\"infocard-evo-split\"):\n",
        "            continue\n",
        "\n",
        "        # if can't find method, from, or to card, skip\n",
        "        method_text = arrow.get_text(\" \", strip=True)\n",
        "        if not method_text:\n",
        "            continue\n",
        "\n",
        "        from_card = arrow.find_previous(\"div\", class_=\"infocard\")\n",
        "        to_card = arrow.find_next(\"div\", class_=\"infocard\")\n",
        "        if not from_card or not to_card:\n",
        "            continue\n",
        "\n",
        "        from_info = extract_evo_card(from_card)\n",
        "        to_info = extract_evo_card(to_card)\n",
        "        if not from_info or not to_info:\n",
        "            continue\n",
        "\n",
        "        edges.append(\n",
        "            {\n",
        "                \"from\": from_info[\"name\"],\n",
        "                \"from_dex\": from_info[\"dex_number\"],\n",
        "                \"to\": to_info[\"name\"],\n",
        "                \"to_dex\": to_info[\"dex_number\"],\n",
        "                \"method\": method_text,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return edges\n"
      ],
      "metadata": {
        "id": "ShywPTRRU0Ai"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# game move methods\n",
        "METHOD_PATTERNS = [\n",
        "    (\"level-up\",  [\"moves learnt by level up\"]),\n",
        "    (\"evolution\", [\"moves learnt on evolution\"]),\n",
        "    (\"egg\",       [\"egg moves\"]),\n",
        "    (\"pre-evo\",   [\"pre-evolution moves\"]),\n",
        "    (\"tm\",        [\"moves learnt by tm\"]),\n",
        "    (\"hm\",        [\"moves learnt by hm\"]),\n",
        "    (\"tr\",        [\"moves learnt by tr\"]),\n",
        "    (\"tutor\",     [\"move tutor moves\", \"tutor moves\"]),\n",
        "    (\"transfer\",  [\"transfer-only moves\"]),\n",
        "]\n",
        "\n",
        "# egg move parents are considered out of scope for the llm\n",
        "IGNORE_METHOD_PATTERNS = [\n",
        "    \"egg move parents\",\n",
        "]\n",
        "\n",
        "# game abbreviations to game name mapping\n",
        "GAME_GROUP_PATTERNS = [\n",
        "    (\"sv\",      [\"scarlet & violet\"]),\n",
        "    (\"lza\",     [\"legends: z-a\"]),\n",
        "\n",
        "    (\"swsh\",    [\"sword & shield\"]),\n",
        "    (\"bdsp\",    [\"brilliant diamond & shining pearl\"]),\n",
        "    (\"la\",      [\"legends: arceus\"]),\n",
        "\n",
        "    (\"usum\",    [\"ultra sun & ultra moon\", \"ultra sun\", \"ultra moon\"]),\n",
        "    (\"sm\",      [\"sun & moon\"]),\n",
        "    (\"lgpe\",    [\"let's go pikachu & let's go eevee\",\n",
        "                 \"lets go pikachu & lets go eevee\"]),\n",
        "\n",
        "    (\"xy\",      [\"x & y\"]),\n",
        "    (\"oras\",    [\"omega ruby\", \"alpha sapphire\"]),\n",
        "\n",
        "    (\"b2w2\",    [\"black 2 & white 2\"]),\n",
        "    (\"bw\",      [\"black & white\"]),\n",
        "\n",
        "    (\"hgss\",    [\"heartgold & soulsilver\"]),\n",
        "    (\"pt\",      [\"platinum\"]),\n",
        "    (\"dp\",      [\"diamond & pearl\"]),\n",
        "\n",
        "    (\"rs\",      [\"ruby & sapphire\"]),\n",
        "    (\"frlg\",    [\"firered & leafgreen\", \"firered\", \"leafgreen\"]),\n",
        "    (\"emerald\", [\"emerald\"]),\n",
        "\n",
        "    (\"gs\",      [\"gold & silver\"]),\n",
        "    (\"crystal\", [\"crystal\"]),\n",
        "\n",
        "    (\"rb\",      [\"red & blue\"]),\n",
        "    (\"y\",       [\"yellow\"]),\n",
        "]\n",
        "\n",
        "def detect_method(title):\n",
        "    t = title.lower()\n",
        "\n",
        "    for ignore in IGNORE_METHOD_PATTERNS:\n",
        "        if ignore in t:\n",
        "            return None\n",
        "\n",
        "    for method, patterns in METHOD_PATTERNS:\n",
        "        if any(p in t for p in patterns):\n",
        "            if method == \"egg\" and not t.startswith(\"egg moves\"):\n",
        "                continue\n",
        "            return method\n",
        "\n",
        "    return None\n",
        "\n",
        "def infer_game_group_id(games_text):\n",
        "    txt = (games_text or \"\").lower()\n",
        "    for code, patterns in GAME_GROUP_PATTERNS:\n",
        "        if any(p in txt for p in patterns):\n",
        "            return code\n",
        "    return \"unknown\"\n",
        "\n",
        "def normalize_headers_in_moves_table(text):\n",
        "    text = text.strip()\n",
        "    mapping = {\n",
        "        \"Lv.\": \"level\",\n",
        "        \"Move\": \"move\",\n",
        "        \"Type\": \"type\",\n",
        "        \"Cat.\": \"category\",\n",
        "        \"Power\": \"power\",\n",
        "        \"Acc.\": \"accuracy\",\n",
        "        \"TM\": \"machine\",\n",
        "        \"HM\": \"machine\",\n",
        "        \"TR\": \"machine\",\n",
        "    }\n",
        "    return mapping.get(text, text.lower())\n",
        "\n",
        "# for each moves table (so same method), get the moves\n",
        "def parse_moves_table(table):\n",
        "    if not isinstance(table, Tag):\n",
        "        return []\n",
        "\n",
        "    header_row = table.find(\"tr\")\n",
        "    if not isinstance(header_row, Tag):\n",
        "        return []\n",
        "\n",
        "    headers_raw = [th.get_text(\" \", strip=True) for th in header_row.find_all([\"th\", \"td\"])]\n",
        "    headers = [normalize_headers_in_moves_table(h) for h in headers_raw]\n",
        "\n",
        "    rows = []\n",
        "    tbody = table.find(\"tbody\") or table\n",
        "    for tr in tbody.find_all(\"tr\"):\n",
        "        if not isinstance(tr, Tag):\n",
        "            continue\n",
        "\n",
        "        cells = tr.find_all(\"td\")\n",
        "        if not cells:\n",
        "            continue\n",
        "        if len(cells) < len(headers):\n",
        "            continue\n",
        "\n",
        "        row = {}\n",
        "        for idx, key in enumerate(headers):\n",
        "            if idx >= len(cells):\n",
        "                continue\n",
        "            cell = cells[idx]\n",
        "            if not isinstance(cell, Tag):\n",
        "                continue\n",
        "            text = cell.get_text(\" \", strip=True)\n",
        "            row[key] = text\n",
        "        rows.append(row)\n",
        "\n",
        "    return rows\n",
        "\n",
        "# for each pokemon game, get the different moves for each method\n",
        "def parse_moves_sections(soup):\n",
        "    sections = []\n",
        "\n",
        "    for h3 in soup.find_all(\"h3\"):\n",
        "        if not isinstance(h3, Tag):\n",
        "            continue\n",
        "\n",
        "        title = h3.get_text(strip=True)\n",
        "        method = detect_method(title)\n",
        "        if method is None:\n",
        "            continue\n",
        "\n",
        "        siblings = []\n",
        "        node = h3.next_sibling\n",
        "        while node is not None:\n",
        "            if isinstance(node, Tag) and node.name == \"h3\":\n",
        "                break\n",
        "            siblings.append(node)\n",
        "            node = node.next_sibling\n",
        "\n",
        "        games_text = None\n",
        "        table = None\n",
        "\n",
        "        for node in siblings:\n",
        "            if not isinstance(node, Tag):\n",
        "                continue\n",
        "\n",
        "            if node.name == \"p\" and games_text is None:\n",
        "                games_text = node.get_text(\" \", strip=True)\n",
        "\n",
        "            if table is None:\n",
        "                t = node.find(\"table\")\n",
        "                if isinstance(t, Tag):\n",
        "                    table = t\n",
        "\n",
        "            if games_text and table:\n",
        "                break\n",
        "\n",
        "        rows = parse_moves_table(table)\n",
        "        sections.append(\n",
        "            {\n",
        "                \"method\": method,\n",
        "                \"games_text\": games_text,\n",
        "                \"rows\": rows,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return sections\n"
      ],
      "metadata": {
        "id": "O3ZFF6n7SaSM"
      },
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classify how pokemon is obtained\n",
        "def infer_location_availability(raw_location: str) -> str:\n",
        "    text = (raw_location or \"\").strip().lower()\n",
        "\n",
        "    if not text or text == \"—\":\n",
        "        return \"unknown\"\n",
        "    if \"not available in this game\" in text:\n",
        "        return \"not-available\"\n",
        "    if \"location data not yet available\" in text:\n",
        "        return \"unknown\"\n",
        "    if \"trade/migrate from another game\" in text:\n",
        "        return \"transfer-only\"\n",
        "    if \"event\" in text:\n",
        "        return \"event-only\"\n",
        "\n",
        "    return \"normal\"\n",
        "\n",
        "# for each entry, put game, availability, and location\n",
        "def parse_locations_section(pokemon_soup) -> list[dict]:\n",
        "    heading = pokemon_soup.find(\n",
        "        lambda tag: tag.name in (\"h2\", \"h3\") and \"Where to find\" in tag.get_text(strip=True)\n",
        "    )\n",
        "    if not heading:\n",
        "        return []\n",
        "\n",
        "    table = None\n",
        "    for sib in heading.next_siblings:\n",
        "        name = getattr(sib, \"name\", None)\n",
        "        if name in (\"h1\", \"h2\", \"h3\"):\n",
        "            break\n",
        "        if name == \"table\":\n",
        "            table = sib\n",
        "            break\n",
        "\n",
        "    if table is None:\n",
        "        return []\n",
        "\n",
        "    entries: list[dict] = []\n",
        "\n",
        "    for row in table.find_all(\"tr\"):\n",
        "        header_cell = row.find(\"th\")\n",
        "        data_cell = row.find(\"td\")\n",
        "        if not header_cell or data_cell is None:\n",
        "            continue\n",
        "\n",
        "        games_text = header_cell.get_text(\" \", strip=True)\n",
        "        raw_location = data_cell.get_text(\" \", strip=True)\n",
        "\n",
        "        location_links = [\n",
        "            a.get_text(\" \", strip=True) for a in data_cell.find_all(\"a\")\n",
        "        ]\n",
        "\n",
        "        availability = infer_location_availability(raw_location)\n",
        "\n",
        "        raw_games = re.split(r\",|/| & | and \", games_text)\n",
        "        games = [g.strip() for g in raw_games if g.strip()]\n",
        "\n",
        "        for game in games:\n",
        "            entries.append(\n",
        "                {\n",
        "                    \"game\": game,\n",
        "                    \"availability\": availability,\n",
        "                    \"raw_location\": raw_location,\n",
        "                    \"location_names\": location_links,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    return entries\n"
      ],
      "metadata": {
        "id": "2SA1_ksXinpr"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Web Scraping"
      ],
      "metadata": {
        "id": "0r21mt-uAZCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get list of all pokemon currently in the pokedex\n",
        "\n",
        "POKEMON_LIST = \"https://pokemondb.net/pokedex/all\"\n",
        "\n",
        "response = requests.get(POKEMON_LIST)\n",
        "pokemon_soup_list = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "pokemon_list = list(dict.fromkeys(pokemon_soup_list.find_all('a', class_=\"ent-name\")))\n",
        "\n",
        "if full_dataset:\n",
        "  pokemon_scope = len(pokemon_list)\n",
        "else:\n",
        "  pokemon_scope =  part_dataset"
      ],
      "metadata": {
        "id": "h6ELdPhy3lke"
      },
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = Path(f'data/{project_name}.jsonl')\n",
        "\n",
        "chunk_groups = {\n",
        "    \"core\": [],\n",
        "    \"training\": [],\n",
        "    \"breeding\": [],\n",
        "    \"statistics\": [],\n",
        "    \"evolutions\": [],\n",
        "    \"moves\": [],\n",
        "    \"locations\": [],\n",
        "}\n",
        "\n",
        "for index, pokemon in enumerate(pokemon_list[:pokemon_scope], start = 1):\n",
        "    pokemon_url = \"https://pokemondb.net\" + pokemon[\"href\"]\n",
        "\n",
        "    response = requests.get(pokemon_url)\n",
        "    pokemon_soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    pokemon_data = get_pokemon_data(pokemon_soup)\n",
        "\n",
        "    chunk_groups[\"core\"].append(build_core_doc(pokemon_data))\n",
        "    chunk_groups[\"training\"].append(build_training_doc(pokemon_data))\n",
        "    chunk_groups[\"breeding\"].append(build_breeding_doc(pokemon_data))\n",
        "    chunk_groups[\"statistics\"].append(build_statistics_doc(pokemon_data))\n",
        "    chunk_groups[\"evolutions\"].append(build_evolution_doc(pokemon_data, pokemon_soup))\n",
        "\n",
        "    gens_to_scrape = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "    for gen in gens_to_scrape:\n",
        "        moves_url = f\"https://pokemondb.net{pokemon['href']}/moves/{gen}\"\n",
        "        resp = requests.get(moves_url)\n",
        "        if resp.status_code != 200:\n",
        "            continue\n",
        "\n",
        "        moves_soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "        move_docs = build_moves_docs_for_generation(pokemon_data, gen, moves_soup)\n",
        "        chunk_groups[\"moves\"].extend(move_docs)\n",
        "\n",
        "    chunk_groups[\"locations\"].append(build_locations_doc(pokemon_data, pokemon_soup))\n"
      ],
      "metadata": {
        "id": "ZFWZeHGP3t6b"
      },
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for group_name, group_chunks in chunk_groups.items():\n",
        "    group_path = output_path.with_name(f\"{output_path.stem}_{group_name}{output_path.suffix}\")\n",
        "\n",
        "    group_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    with group_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        for c in group_chunks:\n",
        "            f.write(json.dumps(c, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "    print(f\"Wrote {len(group_chunks)} documents to {group_path.resolve()}\")"
      ],
      "metadata": {
        "id": "EXGH35i97TOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae952cd-6d23-414d-d34a-d1d72bbe54d0"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote 250 documents to /content/data/pokemon_core.jsonl\n",
            "Wrote 250 documents to /content/data/pokemon_training.jsonl\n",
            "Wrote 250 documents to /content/data/pokemon_breeding.jsonl\n",
            "Wrote 250 documents to /content/data/pokemon_statistics.jsonl\n",
            "Wrote 250 documents to /content/data/pokemon_evolutions.jsonl\n",
            "Wrote 23899 documents to /content/data/pokemon_moves.jsonl\n",
            "Wrote 250 documents to /content/data/pokemon_locations.jsonl\n"
          ]
        }
      ]
    }
  ]
}